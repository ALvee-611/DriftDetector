{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.stats import truncnorm\n",
    "from collections import defaultdict\n",
    "import random\n",
    "from scipy.stats import ks_2samp, chi2_contingency, mannwhitneyu\n",
    "from scipy.stats.contingency import association\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from scipy.spatial.distance import jensenshannon"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Drift Framework"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will try to implement a basic framework to detect data drift. We will go step by step.\n",
    "\n",
    "Before we can start building the framework, we need to have a clear idea of what we mean by data drift.\n",
    "\n",
    "### Step 1: Defining Data drift\n",
    "\n",
    "The data we use for our models are not static. The characteristics od data may change over time. This change could be due to `change in distribution, data quality or structure`, leading to difference between the data we used to train our models and the data it now encounters in production. This drift could be due to change in data sources, change in user behaviour, changes in environment in which data was collected.\n",
    "\n",
    "Data drift can occur if the relationship between the input variables and the target variable changes over time. This is called `Concept Drift`. Data drift can also occur when the distibution of input variables changes over time, but the relationship between input and the target variable remains same. This is called `Covariate Drift`. The underlying problem or context of the data itself might change. This is called `Domain Drift`.\n",
    "\n",
    "Now, we can proceed with defining some functions to simulate syntheic data and then introduce the different data drift in them. We can use them to test our framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(n_samples, new_sample = True):\n",
    "    # Initialize\n",
    "    age_mean = 35\n",
    "    age_std = 10\n",
    "    hourly_rate_mean = 65\n",
    "    hourly_rate_std = 15\n",
    "\n",
    "    distance_param = 0.3 \n",
    "    work_life_bal_param = 3\n",
    "\n",
    "    education_field_cat = ['High School', 'Undergraduate', 'Masters', 'Phd']\n",
    "    education_field_prob = [0.2, 0.4, 0.2, 0.2]\n",
    "    marital_status_cat = ['Married', 'Single', 'Divorced']\n",
    "    marital_status_prob = [0.4, 0.4, 0.2]\n",
    "    gender_cat = ['Male', 'Female']\n",
    "    gender_prob = [0.6, 0.4]\n",
    "\n",
    "    if new_sample:   \n",
    "        # generate continuous variables\n",
    "        age = truncnorm((18 - age_mean) / age_std, (65 - age_mean) / age_std, loc=age_mean, scale=age_std).rvs(size=n_samples).astype(int)\n",
    "        hourly_rate = np.random.normal(hourly_rate_mean, hourly_rate_std, n_samples)\n",
    "        \n",
    "        \n",
    "        # generate discrete variables\n",
    "        distance_from_home = np.random.negative_binomial(distance_param, 1-distance_param, n_samples)\n",
    "        work_life_balance = np.random.poisson(work_life_bal_param, n_samples)\n",
    "\n",
    "        # generate categorical variables\n",
    "        education_level = np.random.choice(education_field_cat, n_samples, p=education_field_prob)\n",
    "        marital_status = np.random.choice(marital_status_cat, n_samples, p=marital_status_prob)\n",
    "        gender = np.random.choice(gender_cat, n_samples, p=gender_prob)\n",
    "\n",
    "    else:\n",
    "        np.random.seed(123)\n",
    "        age = truncnorm((18 - age_mean) / age_std, (65 - age_mean) / age_std, loc=age_mean, scale=age_std).rvs(size=n_samples).astype(int)\n",
    "        hourly_rate = np.random.normal(hourly_rate_mean, hourly_rate_std, n_samples)\n",
    "        \n",
    "        # generate discrete variables\n",
    "        distance_from_home = np.random.negative_binomial(distance_param, 1-distance_param, n_samples)\n",
    "        work_life_balance = np.random.poisson(work_life_bal_param, n_samples)\n",
    "\n",
    "        # generate categorical variables\n",
    "        education_level = np.random.choice(education_field_cat, n_samples, p=education_field_prob)\n",
    "        marital_status = np.random.choice(marital_status_cat, n_samples, p=marital_status_prob)\n",
    "        gender = np.random.choice(gender_cat, n_samples, p=gender_prob)\n",
    "\n",
    "    # combine all variables into a pandas dataframe\n",
    "    data = pd.DataFrame({'Age': age,\n",
    "                        'DistanceFromHome': distance_from_home,\n",
    "                        'Education': education_level,\n",
    "                        'Gender': gender,\n",
    "                        'HourlyRate': hourly_rate,\n",
    "                        'MaritalStatus': marital_status,\n",
    "                        'WorkLifeBalance': work_life_balance,\n",
    "    })\n",
    "\n",
    "    return data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function above generates a dataset with 7 features, each with its own distribution. We can introduce sudden changes in data or gradual changes to a feature in this dataset and have our framework try detect it. This will help us with testing but keeping in mind that the framework should be able to work for any dataset and not just for these features. In other words, this is just one example of a dataset but we will generalise our work and findings for all use cases.\n",
    "\n",
    "We have a function to generate a dataset. Now we need to come up with our target variable. We will have a seperate funtion for that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_label(target_var):\n",
    "    if (target_var['Age'] < 35) and (target_var['Education'] == 'Undergraduate') and (target_var['MaritalStatus'] == 'single'):\n",
    "        return 'Yes'\n",
    "    elif (target_var['Age'] > 45) and (target_var['HourlyRate'] < 45) and (target_var['MaritalStatus'] == 'married'):\n",
    "        return 'Yes'\n",
    "    elif (target_var['WorkLifeBalance'] < 2) and (target_var['Gender'] == 'Male'):\n",
    "        return 'Yes'\n",
    "    elif (target_var['Age'] < 30) and (target_var['Gender'] == 'Female') and (target_var['HourlyRate'] < 35):\n",
    "        return 'Yes'\n",
    "    else:\n",
    "        return 'No'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above will create the target variable for the dummy dataset. Now that we have everything, we can go ahead with creating our dummy dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>DistanceFromHome</th>\n",
       "      <th>Education</th>\n",
       "      <th>Gender</th>\n",
       "      <th>HourlyRate</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>WorkLifeBalance</th>\n",
       "      <th>Atrrition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>Masters</td>\n",
       "      <td>Male</td>\n",
       "      <td>51.420496</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>Phd</td>\n",
       "      <td>Male</td>\n",
       "      <td>63.672120</td>\n",
       "      <td>Married</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>Undergraduate</td>\n",
       "      <td>Female</td>\n",
       "      <td>68.944386</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>2</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>High School</td>\n",
       "      <td>Female</td>\n",
       "      <td>74.630632</td>\n",
       "      <td>Single</td>\n",
       "      <td>3</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>Masters</td>\n",
       "      <td>Male</td>\n",
       "      <td>23.287441</td>\n",
       "      <td>Single</td>\n",
       "      <td>2</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  DistanceFromHome      Education  Gender  HourlyRate MaritalStatus  \\\n",
       "0   40                 0        Masters    Male   51.420496      Divorced   \n",
       "1   30                 2            Phd    Male   63.672120       Married   \n",
       "2   28                 0  Undergraduate  Female   68.944386      Divorced   \n",
       "3   36                 0    High School  Female   74.630632        Single   \n",
       "4   41                 0        Masters    Male   23.287441        Single   \n",
       "\n",
       "   WorkLifeBalance Atrrition  \n",
       "0                0       Yes  \n",
       "1                1       Yes  \n",
       "2                2        No  \n",
       "3                3        No  \n",
       "4                2        No  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drift_df = generate_data(1500, new_sample=False)\n",
    "\n",
    "drift_df['Atrrition'] = drift_df.apply(create_label, axis=1)\n",
    "drift_df.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This concludes `Step 1`. In this step we defined what we mean by data drift and then create a data generating function to create a synthetic dataset that can be used to test our code as we start build it in the new steps."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Creating a function to detect covariate drift\n",
    "\n",
    "We will need a way to compare the distribution of the input features between two sets of data. This will help us determine if the features have the same underlying distribution.\n",
    "\n",
    "#### Step 2.1: Checking the distribution of a single variable between two sets of data to determine if they come from the same underlying distribution.\n",
    "\n",
    "In order to compare the distribution of a single variable between two sets of data, we can use the Kolmogorov-Smirnov test (KS-test). The Null hypothesis for the KS-test is that there is no significant difference between the distribution of the variable between the two datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1500 entries, 0 to 1499\n",
      "Data columns (total 8 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Age               1500 non-null   int32  \n",
      " 1   DistanceFromHome  1500 non-null   int32  \n",
      " 2   Education         1500 non-null   object \n",
      " 3   Gender            1500 non-null   object \n",
      " 4   HourlyRate        1500 non-null   float64\n",
      " 5   MaritalStatus     1500 non-null   object \n",
      " 6   WorkLifeBalance   1500 non-null   int32  \n",
      " 7   Atrrition         1500 non-null   object \n",
      "dtypes: float64(1), int32(3), object(4)\n",
      "memory usage: 76.3+ KB\n"
     ]
    }
   ],
   "source": [
    "drift_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the categorical and numerical feature names\n",
    "\n",
    "def get_num_cat_columns(data):\n",
    "    # Initialize\n",
    "    continuous_columns = []\n",
    "    # all numeric columns\n",
    "    numerical_columns = data.select_dtypes(include=['float', 'int']).columns.tolist()\n",
    "    # all discrete cols\n",
    "    discrete_columns = [col for col in data.columns if data[col].dtype == 'int' and len(data[col].unique()) <= 25]\n",
    "    # all categorical features\n",
    "    categorical_columns = data.select_dtypes(include=['object']).columns.tolist()\n",
    "    # all continuous numeric variables\n",
    "    for i in numerical_columns:\n",
    "        if i not in discrete_columns:\n",
    "            continuous_columns.append(i)\n",
    "    return continuous_columns, discrete_columns, categorical_columns\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above function will help us determine which columns have numerical variables and which fetaures are categorical. KS-test assumes that the variables are continuous and follow a specific distribution. So we will only use it to compare the distribution of the continuous numerical variables between the two datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ks_check(feature,source_one, source_two):\n",
    "    \"\"\" \n",
    "    ks_check(feature,source_one, source_two): compares the distribution of feature between the two datasets source_one and source_two\n",
    "        and returns True if there is a signifiacnt difference and False otherwise\n",
    "    ks_check: Str DataFrame DataFrame -> Bool   \n",
    "    \"\"\"\n",
    "    old_set = source_one[feature]\n",
    "    new_set = source_two[feature]\n",
    "    # if the feature is continuous:\n",
    "    _, p_val = ks_2samp(old_set, new_set)\n",
    "\n",
    "    if p_val < 0.05:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to compare the distribution of the same discrete numerical feature in two datasets, we can use Mann-Whitney U test. It is a non parametric test. It assumes that the two sets being compared are independent and drwan from the same underlying distribution.So, in this case we will assume any difference is due to drift and not because of other factors like data preprocessing and would keep all those factors constant.\n",
    "\n",
    "The Null hypothesis for this test is that the two data sets have the same underlying distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mann_whitney_u_check(feature,source_one, source_two):\n",
    "    \"\"\" \n",
    "    mann_whitney_u_check(feature,source_one, source_two): compares the distribution of feature between the two datasets source_one and source_two\n",
    "        and returns True if there is a signifiacnt difference and False otherwise\n",
    "    mann_whitney_u_check: Str DataFrame DataFrame -> Bool   \n",
    "    \"\"\"\n",
    "    old_set = source_one[feature]\n",
    "    new_set = source_two[feature]\n",
    "    # if the feature is continuous:\n",
    "    _, p_val = mannwhitneyu(old_set, new_set)\n",
    "\n",
    "    if p_val < 0.05:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a way to check covariate drift in numeric features, we will shift our focus to categorical features.\n",
    "\n",
    "We will use Jensen-Shannon divergence (JSD) to look for differences in the underlying distribution of a categorical feature between two datasets by measuring the similarity or difference between two probability distributions.\n",
    "\n",
    "Note that this can fail if there are categories taht are present in one data set but is missing in the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jsd_check(feature,source_one, source_two):\n",
    "    \"\"\" \n",
    "    jsd_check(feature,source_one, source_two): compares the distribution of feature between the two datasets source_one and source_two\n",
    "        and returns True if the difference is high and False otherwise\n",
    "    jsd_check: Str DataFrame DataFrame -> Bool   \n",
    "    \"\"\"\n",
    "    old_set = source_one[feature]\n",
    "    new_set = source_two[feature]\n",
    "    \n",
    "    old_factor, _ = pd.factorize(old_set)\n",
    "    new_factor, _ = pd.factorize(new_set)\n",
    "\n",
    "    old_count = np.bincount(old_factor)\n",
    "    new_count = np.bincount(new_factor)\n",
    "\n",
    "    d = 0.5 * (old_count + new_count)\n",
    "    metric = 0.5 * (jensenshannon(old_count, d) + jensenshannon(new_count, d))\n",
    "\n",
    "    if metric > 0.1:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2.2: Checking the distribution of all variables between two sets of data to determine if they come from the same underlying distributions.\n",
    "\n",
    "Now that we have a way to compare the distributions of all types of features between two datasets, we will combine it all into a single function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_distribution(first_batch,second_batch):\n",
    "    \"\"\"\n",
    "    check_distribution(first_batch,second_batch) takes two sets of data and checks if the underlying distribution of each features\n",
    "      in the two sets of data first_batch and second_batch are same or not. If atleast one feature has significantly different\n",
    "      underlying feature between the two sets of data, it will return the list of names all such featuresfetaure name. If no such feature\n",
    "      is detected is found it will return an empty list\n",
    "    check_distribution: DataFrame DataFrame -> Listof Str\n",
    "    \"\"\"\n",
    "    cont, dis, cat = get_num_cat_columns(first_batch)\n",
    "    cov_drift = []\n",
    "    for i in cont:\n",
    "        if ks_check(i,first_batch, second_batch):\n",
    "            cov_drift.append(i)\n",
    "    for j in dis:\n",
    "        if mann_whitney_u_check(j,first_batch, second_batch):\n",
    "            cov_drift.append(j)\n",
    "    for k in cat:\n",
    "        if jsd_check(k,first_batch, second_batch):\n",
    "            cov_drift.append(k)\n",
    "    return cov_drift\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2.3: Testing our covariate detection function\n",
    "\n",
    "Now that we have the function to detect covariate drift, we need to start testing:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding drift to `Age`, `Education` and `DistanceFromHome`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_drifted_df = pd.DataFrame()\n",
    "\n",
    "new_drifted_df = drift_df.copy()\n",
    "\n",
    "# Adding drift to Age\n",
    "delta = np.linspace(0, new_drifted_df['Age'].mean() * 0.5, len(new_drifted_df))\n",
    "new_drift_data = new_drifted_df['Age'] + delta\n",
    "new_drifted_df['Age'] = new_drift_data\n",
    "\n",
    "# Adding drift to DistanceFromHome\n",
    "n_samples = new_drifted_df.shape[0]\n",
    "distance_param = 0.1\n",
    "distance_from_home = np.random.negative_binomial(distance_param, 1-distance_param, n_samples)\n",
    "\n",
    "education_field_cat = ['High School', 'Undergraduate', 'Masters', 'Phd']\n",
    "education_field_prob = [0.5, 0.1, 0.3, 0.1]\n",
    "education_level = np.random.choice(education_field_cat, n_samples, p=education_field_prob)\n",
    "   \n",
    "new_drifted_df['DistanceFromHome'] = distance_from_home\n",
    "new_drifted_df['Education'] = education_level\n",
    "      \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining two more sets of data that have same underlying distributions since they were generated using the same function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "## No drift added\n",
    "no_drift_df = generate_data(1500, new_sample=True)\n",
    "no_drift_df['Atrrition'] = drift_df.apply(create_label, axis=1)\n",
    "## Anoter set with no drift\n",
    "no_drift_df_2 = generate_data(1500, new_sample=True)\n",
    "no_drift_df_2['Atrrition'] = drift_df.apply(create_label, axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first case, we are checking if our function can detect the three features taht we added drifts to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Age', 'DistanceFromHome', 'Education']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_distribution(drift_df, new_drifted_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seem to successfully detect the covariate drift.\n",
    "\n",
    "We will try our drift detection function on another set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Age', 'DistanceFromHome', 'Education']"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_distribution(no_drift_df, new_drifted_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seem to work as expected and now we can check to see if it returns an empty list when we try to detect drift in features between two sets that were genrated using the same function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_distribution(no_drift_df_2, no_drift_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This also works and expected. Therefore, now that we have tested a few cases, we can move forward with our nect steps:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2.4: Implementing PSI\n",
    "\n",
    "The PSI method will help us ensure that the model we develop using one dataset can be applied to a different dataset. Inorder to implement our PSI function, we will divide the feature we are testing into several bins based on the distribution of the covariate in the old dataset. The bins will then be used to compute the proportion of obsevations in each bin in both sets of data. Finally, the PSI is computed as the sum of the difference between the proportion of observations in each bin in the two sets of data, multiplied by the logarith ratio of the proportion of obervations in each bin."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will compute the PSI for the two different types of features and then combine the two. We will start with numeric features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def psi_numeric(observed, expected):\n",
    "    # Calculate the difference between the mean of the observed and expected data\n",
    "    diff = abs(observed.mean() - expected.mean())\n",
    "    \n",
    "    # Set a threshold for detecting drift\n",
    "    threshold = 0.1 * abs(expected.mean())\n",
    "    \n",
    "    # If the difference exceeds the threshold, return the PSI value\n",
    "    if diff > threshold:\n",
    "        buckets = 10\n",
    "\n",
    "        # Calculate the bucket boundaries\n",
    "        boundaries = np.quantile(observed.index.values, np.linspace(0, 1, buckets + 1))\n",
    "        boundaries[0] = -np.inf\n",
    "        boundaries[-1] = np.inf\n",
    "\n",
    "        # Group the observed and expected data based on the bucket boundaries\n",
    "        observed_groups = observed.groupby(pd.cut(observed.index.values, boundaries)).count()\n",
    "        expected_groups = expected.groupby(pd.cut(expected.index.values, boundaries)).count()\n",
    "\n",
    "        # Calculate the observed and expected proportions for each group\n",
    "        observed_proportions = observed_groups / observed.sum()\n",
    "        expected_proportions = expected_groups / expected.sum()\n",
    "\n",
    "        # Add missing buckets to expected proportions\n",
    "        missing_buckets = observed_proportions.index.difference(expected_proportions.index)\n",
    "        for bucket in missing_buckets:\n",
    "            expected_proportions[bucket] = 0\n",
    "\n",
    "        # Sort the data by the bucket boundaries\n",
    "        observed_proportions.sort_index(inplace=True)\n",
    "        expected_proportions.sort_index(inplace=True)\n",
    "\n",
    "        # Calculate the PSI value\n",
    "        psi_value = np.sum((observed_proportions - expected_proportions) * np.log(observed_proportions / expected_proportions)) * 100\n",
    "\n",
    "        return psi_value\n",
    "    else:\n",
    "        return 0.0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now compute the PSI value for categorical features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def psi_cat(ref_feature, new_feature):\n",
    "    # Calculate distribution of actual and expected values\n",
    "    actual_counts = ref_feature.value_counts(normalize=True, sort=False)\n",
    "    expected_counts = new_feature.value_counts(normalize=True, sort=False)\n",
    "\n",
    "    # Calculate the proportion of each distribution\n",
    "    actual_prop = actual_counts / actual_counts.sum()\n",
    "    expected_prop = expected_counts / expected_counts.sum()\n",
    "\n",
    "    # Calculate the PSI value\n",
    "    psi_value = ((expected_prop - actual_prop) * np.log(expected_prop / actual_prop)).sum()\n",
    "\n",
    "    return psi_value"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining everything:\n",
    "\n",
    "If the PSI value is 0 then there is no change in distribution of the covariate between the two datasets. A PSI value of greater than 0 indicates that the distribution of the covariate has changed between the two datasets, with higher values indicating grater strength."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_psi(old_batch, current_batch):\n",
    "    \"\"\"\n",
    "    calculate_psi(old_batch, current_batch) takes two sets of data and returns the features that may have covariate drift\n",
    "    calculate_psi: DataFrame DataFrame -> Listof Str\n",
    "    \"\"\"\n",
    "    drift_features = []\n",
    "\n",
    "    for feature in old_batch.columns:\n",
    "        df_1 = old_batch[feature]\n",
    "        df_2 = current_batch[feature]\n",
    "\n",
    "        if np.issubdtype(df_1.dtype, np.number):\n",
    "            psi_threshold = 0.1 * abs(df_1.mean())\n",
    "        else:\n",
    "            psi_threshold = 0.1\n",
    "\n",
    "        if np.issubdtype(df_1.dtype, np.number):\n",
    "            stat = psi_numeric(df_1, df_2)\n",
    "\n",
    "            # if stat > optimal_threshold:\n",
    "            if stat > psi_threshold:\n",
    "                drift_features.append(feature)\n",
    "        else:\n",
    "            stat = psi_cat(df_1, df_2)\n",
    "\n",
    "            if stat > psi_threshold:\n",
    "                drift_features.append(feature)\n",
    "    return drift_features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drift",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
